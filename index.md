---
---

The System for AI Lab (SAIL) at Georgia Tech, led by Prof. Alexey Tumanov, specializes in advancing systems support and resource management for machine learning (ML) to democratize large-scale AI systems. Our research encompasses the entire AI infrastructure stack, from foundational system design to the development of efficient ML training and inference algorithms. By focusing on managing the complete ML lifecycle, SAIL aims to enhance accessibility and efficiency in AI technologies.

# Recent News

- Our papers on [Medha](https://arxiv.org/abs/2502.14051) for efficient multi-million context LLM inference and [Maya](https://arxiv.org/pdf/2503.20191) for optimizing deep learning training workloads are now public.
- Congratulations to Prof. Tumanov on being [awarded tenure](https://www.cc.gatech.edu/news/computing-celebrates-2025-faculty-promotion-and-tenure-cases) and promotion to the position of associate professor üéâ.
- RocketKV üöÄ, fast long-context inference with is now KV-cache compression is now on [Arxiv](https://arxiv.org/abs/2502.14051).
- Mnemosyne, our paper on efficient inference up to 10M token context lengths is now [public](https://arxiv.org/abs/2409.17264).
- Our paper on DL training checkpoint compression system, [DynaQuant](https://arxiv.org/abs/2306.11800) has been accepted at SoCC'24.
- [SuperServe](https://arxiv.org/abs/2312.16733) has been accepted at NSDI'25.
- Metron üìê -- our LLM inference system benchmark is now [public](https://x.com/agrawalamey12/status/1812203186494837226).
- [DŒµpS](https://arxiv.org/abs/2407.06167) and [SuperFedNAS](https://arxiv.org/abs/2301.10879) have been accepted at ECCV'24.
- Congratulations to [Prof. Alexey Tumanov](/members/alexey-tumanov) for being awarded college of computing outstanding junior faculty teaching award.
- Sarathi-Serve ‚ò∏Ô∏è, our paper on efficient LLM inference has been accepted at OSDI'24.
- Vidur üë≥üèΩ, our paper on large scale LLM inference cluster simulation has been accepted at MLSys'24.
- [Payman Behnam](/members/payman-behnam) awarded [NVIDIA Graduate Fellowship 2024](https://blogs.nvidia.com/blog/graduate-research-fellowships-for-2024/) for advancing machine learning and systems with high-performance, low-latency, and energy-efficient hardware designs.
- [Payman Behnam](/members/payman-behnam) receives [Qualcomm Innovation Fellowship 2023](https://www.qualcomm.com/research/university-relations/innovation-fellowship/winners) for his work on Hardware-Software Co-Design for DNN inference systems.
- [Amey Agrawal](/members/amey-agrawal) secures [CRNCH PhD Fellowship 2023](https://crnch.gatech.edu/phd-fellowships-awarded/) for his research in LLM inference.
